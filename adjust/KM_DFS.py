import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from lifelines import KaplanMeierFitter
from lifelines.statistics import logrank_test
from lifelines.utils import median_survival_times

#å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®š
input_path = "/Users/rshibaki/Library/CloudStorage/GoogleDrive-ryota.shibaki@gmail.com/ãƒã‚¤ãƒˆã‚™ãƒ©ã‚¤ãƒ•ã‚™/ADJUSTè©¦é¨“/DATA/dataset_250129.xlsx"
output_dir = "Figure"

df = pd.read_excel(input_path, sheet_name="dataset", engine="openpyxl")

# DFS_mainã®ä½œå›³
df_dfs_main = df[df["STUDY"] == 0][["DFSMONTHS", "DFS_event"]].dropna()

# âœ… KaplanMeierFitter ã‚’ä½¿ç”¨ã—ã¦ç”Ÿå­˜åˆ†æ
km_dfs_main = KaplanMeierFitter()
km_dfs_main.fit(df_dfs_main["DFSMONTHS"], event_observed=df_dfs_main["DFS_event"])

# ğŸ“ˆ ãƒ—ãƒ­ãƒƒãƒˆè¨­å®š
plt.rcParams["font.family"] = "Arial"
fig, ax = plt.subplots(figsize=(8, 6))
plt.subplots_adjust(bottom=0.35)

# ç”Ÿå­˜æ›²ç·šã¨95%ä¿¡é ¼åŒºé–“ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
km_dfs_main.plot_survival_function(ax=ax, ci_show=True, linewidth=2, color="blue", legend=False)

# # ğŸ“Œ 0 ã‹ã‚‰å§‹ã¾ã‚‹ã‚ˆã†ã«æ‰‹å‹•ã§ (0, 1.0) ã‚’è¿½åŠ  + æ¿ƒã„æ°´è‰²ã®ãƒ©ã‚¤ãƒ³ã‚’è¨­å®š
# ax.step(np.insert(km_dfs_main.timeline, 0, 0), np.insert(km_dfs_main.survival_function_.values.flatten(), 0, 1.0), 
#     where="post", label="Kaplan-Meier Estimate", linewidth=2, color="blue")

# ğŸ”´ ã‚»ãƒ³ã‚µãƒªãƒ³ã‚°ï¼ˆæ‰“ã¡åˆ‡ã‚Šãƒ‡ãƒ¼ã‚¿ï¼‰ã®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ¿ƒã„æ°´è‰²ï¼‰
censor_times = df_dfs_main["DFSMONTHS"][df_dfs_main["DFS_event"] == 0]
censor_probs = km_dfs_main.survival_function_at_times(censor_times).values  # å„æ‰“ã¡åˆ‡ã‚Šæ™‚ç‚¹ã®ç”Ÿå­˜ç¢ºç‡

ax.scatter(censor_times, censor_probs, color='blue', marker='|', s=100, label="Censored")

# ğŸ“Œ è»¸ã®ç¯„å›²ã‚’é©åˆ‡ã«è¨­å®š
ax.set_xlabel("Time (months)", fontsize=12, labelpad=8)
ax.set_ylabel("Survival Probability", fontsize=12)
ax.set_ylim(0, 1.05)
ax.set_xlim(0, df_dfs_main["DFSMONTHS"].max() + 5)


# ğŸ“Œ å¤‰æ›´ç‚¹: è»¸ã®ãƒ¡ãƒ¢ãƒªã‚’è¨­å®š
ax.set_xticks(np.arange(0, df_dfs_main["DFSMONTHS"].max() + 12, 12))
ax.set_yticks(np.arange(0, 1.1, 0.2))

# è£œåŠ©ãƒ¡ãƒ¢ãƒªã®è¿½åŠ ï¼ˆ6ãƒ¶æœˆã”ã¨ã€0.1ã”ã¨ï¼‰
ax.minorticks_on()
ax.xaxis.set_minor_locator(plt.MultipleLocator(6))
ax.yaxis.set_minor_locator(plt.MultipleLocator(0.1))

# ğŸ“Œ å¤‰æ›´ç‚¹: 12, 24, 36ãƒ¶æœˆã®ä½ç½®ã«è£œåŠ©ç·šï¼ˆç¸¦ç·šï¼‰ã‚’è¿½åŠ 
for x in [12, 24, 36]:
    ax.axvline(x=x, linestyle="--", color="gray", alpha=0.7)  # è£œåŠ©ç·š

# ğŸ“Œ å¤‰æ›´ç‚¹: 12, 24, 36ãƒ¶æœˆã®ç”Ÿå­˜å‰²åˆã‚’ã‚°ãƒ©ãƒ•ã«è¡¨ç¤º
for x in [12, 24, 36]:
    if x in km_dfs_main.timeline:
        survival_prob = km_dfs_main.survival_function_at_times([x]).values[0]
        ax.text(x, survival_prob + 0.03, f"{survival_prob*100:.1f}%", fontsize=10, color="black", ha="right")

# ğŸ“Œ Number at Risk ã‚’è¿½åŠ 
risk_times = [0, 6, 12, 18, 24, 30, 36, 42]
risk_counts = [df_dfs_main[df_dfs_main["DFSMONTHS"] >= t].shape[0] for t in risk_times]

for i, (t, r) in enumerate(zip(risk_times, risk_counts)):
    ax.text(t, -0.30, f"{r}", fontsize=12, color="black", ha="center")

# ğŸ“Œ Number at Risk ã®ãƒ©ãƒ™ãƒ«
ax.text(-2, -0.30, "Number at Risk", fontsize=12, ha="right")

#PNGå½¢å¼ã§ã‚°ãƒ©ãƒ•ã‚’ãƒ•ã‚©ãƒ«ãƒ€ã«å‡ºåŠ›
output_filename = "KaplanMeier_DFS_main.png"
output_path = os.path.join(output_dir, output_filename)
plt.savefig(output_path, dpi=300, bbox_inches="tight")


# DFS integrated analysis (matching 1: 1)
# STUDY == 0 ã®ãƒ‡ãƒ¼ã‚¿
df_dfs_integ_0 = df[df["STUDY"] == 0][["DFSMONTHS", "DFS_event"]].dropna()
df_dfs_integ_0.columns = ["DFSMONTHS", "DFS_event"]

# STUDY == 1 ã®ãƒ‡ãƒ¼ã‚¿
df_dfs_integ_1 = df[df["STUDY"] == 1][["DFSMONTHS", "DFS_event"]].dropna()
df_dfs_integ_1.columns = ["DFSMONTHS", "DFS_event"]

# KaplanMeierFitter ã‚’ä½¿ç”¨
km_dfs_0 = KaplanMeierFitter()
km_dfs_1 = KaplanMeierFitter()

km_dfs_0.fit(df_dfs_integ_0["DFSMONTHS"], event_observed=df_dfs_integ_0["DFS_event"])
km_dfs_1.fit(df_dfs_integ_1["DFSMONTHS"], event_observed=df_dfs_integ_1["DFS_event"])

plt.rcParams["font.family"] = "Arial"
fig, ax = plt.subplots(figsize=(8, 6))
plt.subplots_adjust(bottom=0.4)

# STUDY == 0 ç”Ÿå­˜æ›²ç·šã¨95%ä¿¡é ¼åŒºé–“ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
km_dfs_0.plot_survival_function(ax=ax, ci_show=True, ci_alpha=0.1, linewidth=2, color="#CE1C48", label="Atezo+CDDP+VNR")

# STUDY == 1 ç”Ÿå­˜æ›²ç·šã¨95%ä¿¡é ¼åŒºé–“ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
km_dfs_1.plot_survival_function(ax=ax, ci_show=True, ci_alpha=0.1, linewidth=2, color="#1180D9", label="Matched CDDP+VNR")

# ã‚»ãƒ³ã‚µãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ­ãƒƒãƒˆ
censor_times_0 = df_dfs_integ_0["DFSMONTHS"][df_dfs_integ_0["DFS_event"] == 0]
censor_probs_0 = km_dfs_0.survival_function_at_times(censor_times_0).values
ax.scatter(censor_times_0, censor_probs_0, color='#CE1C48', marker='|', s=100)

censor_times_1 = df_dfs_integ_1["DFSMONTHS"][df_dfs_integ_1["DFS_event"] == 0]
censor_probs_1 = km_dfs_1.survival_function_at_times(censor_times_1).values
ax.scatter(censor_times_1, censor_probs_1, color='#1180D9', marker='|', s=100)

ax.set_xlabel("Months since Registration", fontsize=12, labelpad=8)
ax.set_ylabel("Probability of Disease-free Survival", fontsize=12)
ax.set_ylim(0, 1.05)

# ä»¥å‰ã®æ¨ªè»¸ã®æœ€å¤§å€¤ã‚’ä½¿ç”¨
x_max = df_dfs_main["DFSMONTHS"].max() # ä»¥å‰ã®æœ€å¤§å€¤ã‚’ä½¿ç”¨
ax.set_xlim(0, x_max + 5)

ax.set_xticks(np.arange(0, x_max + 5, 12))
ax.set_yticks(np.arange(0, 1.1, 0.2))

ax.minorticks_on()
ax.xaxis.set_minor_locator(plt.MultipleLocator(6))
ax.yaxis.set_minor_locator(plt.MultipleLocator(0.1))

# 12, 24, 36ãƒ¶æœˆã®è£œåŠ©ç·š
for x in [12, 24, 36]:
    ax.axvline(x=x, linestyle="--", color="gray", alpha=0.7)

# 12, 24, 36ãƒ¶æœˆã®ç”Ÿå­˜å‰²åˆã‚’ã‚°ãƒ©ãƒ•ã«è¡¨ç¤º
for x in [12, 24, 36]:
    if x in km_dfs_0.timeline:
        survival_prob_0 = km_dfs_0.survival_function_at_times([x]).values[0]
        ax.text(x, survival_prob_0 + 0.03, f"{survival_prob_0*100:.1f}%", fontsize=10, color="blue", ha="right")

    if x in km_dfs_1.timeline:
        survival_prob_1 = km_dfs_1.survival_function_at_times([x]).values[0]
        ax.text(x, survival_prob_1 + 0.03, f"{survival_prob_1*100:.1f}%", fontsize=10, color="red", ha="right")

# Number at Risk
risk_times = [0, 6, 12, 18, 24, 30, 36, 42]
risk_counts_0 = [df_dfs_integ_0[df_dfs_integ_0["DFSMONTHS"] >= t].shape[0] for t in risk_times]
risk_counts_1 = [df_dfs_integ_1[df_dfs_integ_1["DFSMONTHS"] >= t].shape[0] for t in risk_times]

for i, (t, r0, r1) in enumerate(zip(risk_times, risk_counts_0, risk_counts_1)):
    ax.text(t, -0.35, f"{r0}", fontsize=12, color="#CE1C48", ha="center")
    ax.text(t, -0.40, f"{r1}", fontsize=12, color="#1180D9", ha="center")

ax.text(-2, -0.30, "Number at risk", fontsize=12, ha="right", color="black")
ax.text(-2, -0.35, "Atezo+CDDP+VNR", fontsize=12, ha="right", color="#CE1C48")
ax.text(-2, -0.40, "Matched CDDP+VNR", fontsize=12, ha="right", color="#1180D9")

ax.legend(fontsize=10)

#PNGå½¢å¼ã§ã‚°ãƒ©ãƒ•ã‚’ãƒ•ã‚©ãƒ«ãƒ€ã«å‡ºåŠ›
output_filename = "KaplanMeier_DFS_inte.png"
output_path = os.path.join(output_dir, output_filename)
plt.savefig(output_path, dpi=300, bbox_inches="tight")

# DFS integrated analysis (matching 1: 1)ã®ç”Ÿå­˜å‰²åˆ
# æŒ‡å®šã—ãŸæ™‚ç‚¹ã®ç”Ÿå­˜ç¢ºç‡ã‚’å–å¾—
time_points = [12, 24, 36, 48]
survival_probabilities0 = km_dfs_0.survival_function_at_times(time_points)
survival_probabilities1 = km_dfs_1.survival_function_at_times(time_points)

# ç”Ÿå­˜ä¸­å¤®å€¤ã¨95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—
median_survival_0 = km_dfs_0.median_survival_time_
median_survival_1 = km_dfs_1.median_survival_time_

# 95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—
ci_0 = km_dfs_0.confidence_interval_survival_function_
ci_1 = km_dfs_1.confidence_interval_survival_function_

# ãƒ­ã‚°ãƒ©ãƒ³ã‚¯æ¤œå®šã®å®Ÿæ–½
logrank_result = logrank_test(
    df_dfs_integ_0["DFSMONTHS"], df_dfs_integ_1["DFSMONTHS"],
    event_observed_A=df_dfs_integ_0["DFS_event"], event_observed_B=df_dfs_integ_1["DFS_event"]
)

# På€¤ã‚’å–å¾—
p_value = logrank_result.p_value

# ãƒã‚¶ãƒ¼ãƒ‰æ¯” (HR) ã®è¨ˆç®—
hr = km_dfs_1.event_table.observed.sum() / km_dfs_0.event_table.observed.sum()

# 95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ï¼ˆã‚«ãƒ—ãƒ©ãƒ³ãƒã‚¤ãƒ¤ãƒ¼æ¨å®šæ³•ã«ã‚ˆã‚‹è¿‘ä¼¼ï¼‰
ci_lower = np.exp(np.log(hr) - 1.96 * np.sqrt(1/km_dfs_1.event_table.observed.sum() + 1/km_dfs_0.event_table.observed.sum()))
ci_upper = np.exp(np.log(hr) + 1.96 * np.sqrt(1/km_dfs_1.event_table.observed.sum() + 1/km_dfs_0.event_table.observed.sum()))

# 80%ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—
km_dfs_0_80 = KaplanMeierFitter(alpha=0.20)
km_dfs_1_80 = KaplanMeierFitter(alpha=0.20)

km_dfs_0_80.fit(df_dfs_integ_0["DFSMONTHS"], event_observed=df_dfs_integ_0["DFS_event"])
km_dfs_1_80.fit(df_dfs_integ_1["DFSMONTHS"], event_observed=df_dfs_integ_1["DFS_event"])

ci_0_80 = km_dfs_0_80.confidence_interval_survival_function_
ci_1_80 = km_dfs_1_80.confidence_interval_survival_function_

# 24ãƒ¶æœˆã§ã®80%ä¿¡é ¼åŒºé–“ã‚’å–å¾—
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ˜‡é †ã«ã‚½ãƒ¼ãƒˆï¼ˆå¿µã®ãŸã‚ï¼‰
ci_0_80_sorted = ci_0_80.sort_index()
ci_1_80_sorted = ci_1_80.sort_index()

# 24ãƒ¶æœˆä»¥ä¸‹ã®æœ€å¤§ã®æ™‚ç‚¹ã‚’å–å¾—
asof_idx_0 = ci_0_80_sorted.index[ci_0_80_sorted.index <= 24].max()
asof_idx_1 = ci_1_80_sorted.index[ci_1_80_sorted.index <= 24].max()

# ãã‚Œã‚’ loc ã§å–å¾—
ci_0_80_at_24 = ci_0_80_sorted.loc[[asof_idx_0]]
ci_1_80_at_24 = ci_1_80_sorted.loc[[asof_idx_1]]

# âœ… ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®š
output_filename_txt = "KM_DFS_probabilities.txt"
output_path_txt = os.path.join(output_dir, output_filename_txt)

# âœ… ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ä¿å­˜
with open(output_path_txt, "w") as f:
    f.write("\n2å¹´DFSå‰²åˆã¨80%ä¿¡é ¼åŒºé–“\n")
    f.write("="*40 + "\n\n")
    
    # 24ãƒ¶æœˆã®ç”Ÿå­˜ç¢ºç‡
    dfs_24_0 = survival_probabilities0.loc[24]
    dfs_24_1 = survival_probabilities1.loc[24]

    # 80%ä¿¡é ¼åŒºé–“ï¼ˆä¸‹é™ãƒ»ä¸Šé™ï¼‰
    ci_lower_0_80 = ci_0_80_at_24.iloc[0, 0]
    ci_upper_0_80 = ci_0_80_at_24.iloc[0, 1]
    ci_lower_1_80 = ci_1_80_at_24.iloc[0, 0]
    ci_upper_1_80 = ci_1_80_at_24.iloc[0, 1]

    f.write(f"ADJUSTç¾¤ (24ãƒ¶æœˆ): {dfs_24_0*100:.1f}% (80% CI: {ci_lower_0_80*100:.1f}% - {ci_upper_0_80*100:.1f}%)\n")
    f.write(f"IMPACTç¾¤ (24ãƒ¶æœˆ): {dfs_24_1*100:.1f}% (80% CI: {ci_lower_1_80*100:.1f}% - {ci_upper_1_80*100:.1f}%)\n")

    f.write("Survival probabilities\n")
    f.write("="*40 + "\n\n")
    f.write("Time (months)\tSurvival Probability\n")  # ãƒ˜ãƒƒãƒ€ãƒ¼
    f.write("ADJUST study\n")
    for time, prob in zip(time_points, survival_probabilities0.values.flatten()):
        f.write(f"{time}\t{prob:.4f}\n")  # ã‚¿ãƒ–åŒºåˆ‡ã‚Šã§ä¿å­˜
    f.write("IMPACT study\n")
    for time, prob in zip(time_points, survival_probabilities1.values.flatten()):
        f.write(f"{time}\t{prob:.4f}\n")  # ã‚¿ãƒ–åŒºåˆ‡ã‚Šã§ä¿å­˜
    
    f.write("\nKaplan-Meier ç”Ÿå­˜è§£æçµæœ\n")
    f.write("="*40 + "\n\n")

    # âœ… ç”Ÿå­˜ä¸­å¤®å€¤ã®æ›¸ãè¾¼ã¿
    f.write(f"ç”Ÿå­˜ä¸­å¤®å€¤ (Median Survival Time):\n")
    f.write(f"  - ADJUSTç¾¤ 0: {median_survival_0:.2f} ãƒ¶æœˆ\n")
    f.write(f"  - IMPACTç¾¤ 1: {median_survival_1:.2f} ãƒ¶æœˆ\n\n")

    # âœ… 95% ä¿¡é ¼åŒºé–“ã®æ›¸ãè¾¼ã¿
    f.write("95% ä¿¡é ¼åŒºé–“ (Confidence Interval):\n")
    f.write(f"  - ADJUSTç¾¤ 0: {ci_0.iloc[:, 0].min():.2f} - {ci_0.iloc[:, 0].max():.2f} ãƒ¶æœˆ\n")
    f.write(f"  - IMPACTç¾¤ 1: {ci_1.iloc[:, 0].min():.2f} - {ci_1.iloc[:, 0].max():.2f} ãƒ¶æœˆ\n\n")

    # âœ… ãƒ­ã‚°ãƒ©ãƒ³ã‚¯æ¤œå®šã®På€¤ã®æ›¸ãè¾¼ã¿
    f.write(f"ãƒ­ã‚°ãƒ©ãƒ³ã‚¯æ¤œå®š (Log-rank test):\n")
    f.write(f"  - På€¤: {p_value:.4f}\n\n")

    # âœ… ãƒã‚¶ãƒ¼ãƒ‰æ¯” (HR) ã¨ 95% ä¿¡é ¼åŒºé–“ã®æ›¸ãè¾¼ã¿
    f.write(f"ãƒã‚¶ãƒ¼ãƒ‰æ¯” (Hazard Ratio, HR):\n")
    f.write(f"  - HR: {hr:.2f}\n")
    f.write(f"  - 95% CI: {ci_lower:.2f} - {ci_upper:.2f}\n\n")

print(f"âœ… txtãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path_txt}")